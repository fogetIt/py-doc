CPU 调度
--------
    - 某一时间点 **1** 个 CPU 只能分配给 **1** 个进程
        - 多核处理器
            - 相当于多个 **CPU**，同一时间点能运行多个进程
            - 同样的核心数，多核比多 **U**
                - 成本低
                - 性能好
                - 主板设计简单
                - 功耗低
                - 体积小
                - 数据共享容易
    - 一般情况下， **CPU** 远远快于寄存器、 **RAM** 和其它设备

    :抢占式调度: 操作系统负责分配 **CPU** 时间给等待队列中的各个进程

        :操作系统进程调度:
            - 一旦当前的进程使用完分配的 **CPU** 时间，发出一个信号
            - 操作系统响应这个信号，开始进程调度，运行下一个线程/进程
            - 所以任何一个线程都不能独占 **CPU**
            - 每个线程占用 **CPU** 的时间取决于进程和操作系统
        :**python** 线程调度: 在 **python** 中通过软件模拟（时钟）中断信号，来实现线程调度
    :非抢占的调度: 某个线程需要多少 **CPU** 时间就占用多少 **CPU** 时间

        - 占用 **CPU** 的线程拥有对 **CPU** 的控制权
            - 只有它自己主动释放 **CPU** ，其他的线程才可以使用
        - 其他所有需要 **CPU** 的线程都可能“饿死”
        - 在处理机空闲，即该进程没有使用 **CPU** 时，系统可以允许其他的进程暂时使用 **CPU**
-----

:超线程技术: 利用特殊的硬件指令，把两个逻辑内核模拟成两个物理芯片


并发编程
-------
    :process: 进程

        - 应用程序的一次执行实例
            - 程序没有生命，只有 **CPU** 赋予程序生命时，它才能成为一个活动的实体
            - 正常情况下 **避免在一台机器上同时运行同一应用程序的多个实例**
        - 包含上下文切换的程序执行时间总和
            - **CPU** 加载上下文 + **CPU** 执行 + **CPU** 保存上下文
        - 线程的容器，包含 **1~*** 个线程
        :thread: 线程

            - 进程的组成部分
                - 操作系统创建一个进程后，该进程会自动申请一个主线程
            - 共享了进程上下文环境，把进程的 **CPU** 分成更为细小的时间切片
                - 线程有自己的栈和栈指针、程序计数器、寄存器等
                - 线程之间互不影响，有开始、运行、结束三个状态
            - 缺点
                - 进程内部有线程数目的限制
                - 随着并发量的增加，线程生成和切换的成本也变得昂贵
            :coroutine: 协程

                - 一种用户态的轻量级线程（微线程、纤程）
                - 在 **1** 个线程中规定代码块执行顺序
                    - 协程拥有自己的寄存器上下文和栈
                        - 协程能保留上一次调用时的状态
                        - 协程调度切换时，将寄存器上下文和栈保存到其他地方
                        - 切回来时，恢复先前保存的寄存器上下文和栈
                        - 每次过程重入时，就相当于进入上一次调用的状态，进入上一次离开时所处逻辑流的位置
                    - 一个线程内可以同时存在多个协程，但是只有 **1** 个是激活的


并发/并行
--------
    :并发:
        - 总进程数 > **CPU** 数
        :时间片轮转进程调度: 物理 **CPU** 在若干程序之间多路复用

            - 在操作系统的管理下，所有正在运行的进程轮流使用 **CPU**
            - 每个进程允许占用 **CPU** 的时间非常短，用户感觉不出 **CPU** 在轮流为多个进程服务，所有进程好象都在不间断地运行一样
        - 对有限物理资源强制行使多用户共享以提高效率
    :并行:
        - 总进程数 <= **CPU** 数
        :多个进程真正同时运行: 不同的进程分配给不同的 **CPU** 来运行
    - 并行运行的效率显然高于并发运行，所以在多 **CPU** 的计算机中，多任务的效率比较高
    - 但是，如果在多 **CPU** 计算机中只运行一个进程，就不能发挥多 **CPU** 的优势
